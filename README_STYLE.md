# WikiArt Style Classifier

Classification simple-tÃ¢che pour la prÃ©diction de styles artistiques uniquement.

## ğŸ“ Nouveaux Fichiers

Cette implÃ©mentation ajoute les fichiers suivants sans modifier les fichiers existants :

```
adl/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ style_classifier.py     # ModÃ¨le de classification de style
â”œâ”€â”€ dataset_style.py             # Dataset simplifiÃ© (style uniquement)
â”œâ”€â”€ train_style.py               # Script d'entraÃ®nement
â”œâ”€â”€ test_style_model.py          # Script d'infÃ©rence
â”œâ”€â”€ checkpoints_style/           # Checkpoints du modÃ¨le style
â””â”€â”€ README_STYLE.md              # Cette documentation
```

## ğŸ¯ Architecture

### ModÃ¨le

```
Image (224x224x3)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ViT Backbone  â”‚  <- timm (ImageNet) ou CLIP
â”‚  (frozen ou     â”‚
â”‚   fine-tuned)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  Features [CLS]
  (768 dim)
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  MLP Head   â”‚  (768 â†’ 1536 â†’ 22)
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    22 classes
```

### DiffÃ©rences avec le classificateur multi-tÃ¢che

| Aspect | Multi-tÃ¢che | Style seul |
|--------|-------------|------------|
| **TÃ¢ches** | Style + Artiste | Style uniquement |
| **TÃªtes** | 2 tÃªtes MLP | 1 tÃªte MLP |
| **Loss** | CombinÃ©e pondÃ©rÃ©e | Simple (Focal/CE) |
| **ComplexitÃ©** | Plus Ã©levÃ©e | SimplifiÃ©e |
| **Performance** | LÃ©gÃ¨rement infÃ©rieure sur style | OptimisÃ©e pour style |
| **EntraÃ®nement** | ~6 heures | ~4 heures |

## ğŸš€ Installation

Utilise les mÃªmes dÃ©pendances que le projet principal :

```bash
pip install -r requirements.txt
```

## ğŸ“Š EntraÃ®nement

### EntraÃ®nement par dÃ©faut

```bash
python train_style.py
```

Configuration par dÃ©faut :
- **Backbone**: CLIP ViT-B/16
- **Batch size**: 192
- **Phase 1**: 15 epochs (backbone gelÃ©)
- **Phase 2**: 25 epochs (fine-tuning)
- **Loss**: Focal Loss + Label Smoothing
- **Augmentation**: Strong (combat overfitting)

### Options d'entraÃ®nement

```bash
# Utiliser timm au lieu de CLIP
python train_style.py --backbone-type timm

# Ajuster les hyperparamÃ¨tres
python train_style.py --batch-size 128 --phase1-epochs 10 --phase2-epochs 20

# DÃ©sactiver mixed precision (pour debugging)
python train_style.py --no-amp

# Changer le dossier de sauvegarde
python train_style.py --save-dir my_checkpoints
```

### StratÃ©gie d'entraÃ®nement

**Phase 1** (15 epochs) :
- Backbone **gelÃ©**
- EntraÃ®nement de la tÃªte uniquement
- LR: 5e-4
- Warmup: 3 epochs
- Scheduler: CosineAnnealing

**Phase 2** (25 epochs) :
- DÃ©gel des 4 derniÃ¨res couches du backbone
- Fine-tuning progressif
- LR diffÃ©rentiels:
  - Backbone: 5e-6
  - Head: 5e-5
- Early stopping: patience=4

## ğŸ§ª Test / InfÃ©rence

### Tester une image

```bash
# Mode interactif (choisir le checkpoint)
python test_style_model.py

# Tester une image spÃ©cifique
python test_style_model.py --image path/to/image.jpg

# Utiliser le meilleur modÃ¨le avec top-3
python test_style_model.py --checkpoint best --top-k 3
```

### Exemple de sortie

```
============================================================
ğŸ“· Image: monet_waterlilies.jpg
   Dimensions: 800x600
============================================================

ğŸ¨ STYLE:
----------------------------------------
  1. Impressionism                    87.3% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  2. Post_Impressionism               8.2% â–ˆ
  3. Pointillism                      2.1%
  4. Fauvism                          1.4%
  5. Expressionism                    0.7%
```

### Lister les checkpoints disponibles

```bash
python test_style_model.py --list-checkpoints
```

## ğŸ“ˆ MÃ©triques attendues

BasÃ© sur l'architecture et la configuration :

| MÃ©trique | Cible | Note |
|----------|-------|------|
| **Top-1 Accuracy** | >75% | AmÃ©lioration vs multi-tÃ¢che |
| **Top-5 Accuracy** | >95% | Excellente couverture |
| **Loss (test)** | <0.4 | Avec label smoothing |

### Comparaison multi-tÃ¢che vs simple-tÃ¢che

| ModÃ¨le | Top-1 (style) | Top-5 (style) | Temps entraÃ®nement |
|--------|---------------|---------------|-------------------|
| Multi-tÃ¢che | 70-75% | 90-95% | ~6h |
| **Style seul** | **75-80%** | **95%+** | **~4h** |

**Avantages du style seul** :
- âœ… Focus complet sur la tÃ¢che de style
- âœ… Pas de compromis avec la tÃ¢che artiste
- âœ… EntraÃ®nement plus rapide
- âœ… ModÃ¨le plus lÃ©ger (une seule tÃªte)
- âœ… Plus simple Ã  maintenir

## ğŸ”§ HyperparamÃ¨tres

### Configuration complÃ¨te

```python
DEFAULT_CONFIG = {
    # DonnÃ©es
    "batch_size": 192,          # OptimisÃ© pour GPU 24GB
    "num_workers": 8,

    # ModÃ¨le
    "backbone": "ViT-B-16",
    "backbone_type": "clip",     # "timm" ou "clip"
    "dropout": 0.3,

    # Phase 1 (backbone gelÃ©)
    "phase1_epochs": 15,
    "phase1_lr": 5e-4,

    # Phase 2 (fine-tuning)
    "phase2_epochs": 25,
    "phase2_lr_backbone": 5e-6,  # LR faible pour backbone
    "phase2_lr_head": 5e-5,      # LR plus Ã©levÃ© pour head
    "unfreeze_layers": 4,         # Nombre de couches dÃ©gelÃ©es

    # Optimisation
    "weight_decay": 0.05,
    "warmup_epochs": 3,
    "use_amp": True,              # Mixed precision

    # Loss
    "use_focal_loss": True,
    "focal_gamma": 2.0,
    "label_smoothing": 0.1,

    # Early Stopping
    "early_stopping_patience": 4,
    "early_stopping_min_delta": 0.001,
}
```

## ğŸ“¦ Structure du code

### `models/style_classifier.py`

**Classes principales** :
- `StyleClassifier`: ModÃ¨le principal (ViT + MLP head)
- `StyleLoss`: Loss avec support Focal/CrossEntropy
- `FocalLoss`: Focal Loss pour dÃ©sÃ©quilibre de classes
- `LabelSmoothingFocalLoss`: Focal Loss + Label Smoothing
- `CLIPVisionBackbone`: Wrapper pour CLIP

**Fonctions utilitaires** :
- `create_style_classifier()`: Factory pour crÃ©er le modÃ¨le

### `dataset_style.py`

**Classes principales** :
- `WikiArtStyleDataset`: Dataset PyTorch (style uniquement)

**Fonctions utilitaires** :
- `get_transforms()`: Transforms train/val/test
- `create_splits()`: Splits stratifiÃ©s
- `create_dataloaders()`: DataLoaders avec weighted sampling
- `get_class_weights()`: Poids pour loss pondÃ©rÃ©e

### `train_style.py`

**Classes utilitaires** :
- `MetricTracker`: Suivi des mÃ©triques
- `EarlyStopping`: ArrÃªt anticipÃ©

**Fonctions principales** :
- `train_one_epoch()`: EntraÃ®nement sur une epoch
- `validate()`: Validation
- `train()`: Boucle complÃ¨te (phase 1 + phase 2)

## ğŸ¨ Styles supportÃ©s

22 styles artistiques :

```
Abstract_Expressionism, Action_painting, Analytical_Cubism,
Art_Nouveau_Modern, Baroque, Color_Field_Painting,
Contemporary_Realism, Cubism, Early_Renaissance, Expressionism,
Fauvism, High_Renaissance, Impressionism, Mannerism_Late_Renaissance,
Minimalism, Naive_Art_Primitivism, New_Realism, Northern_Renaissance,
Pointillism, Pop_Art, Post_Impressionism, Realism
```

## ğŸ” Monitoring

### TensorBoard

```bash
tensorboard --logdir checkpoints_style/TIMESTAMP/tensorboard
```

MÃ©triques trackÃ©es :
- Loss (train/val)
- Top-1 Accuracy (train/val)
- Top-5 Accuracy (train/val)
- Learning Rate (head + backbone)
- Temps par epoch

### Fichiers sauvegardÃ©s

```
checkpoints_style/TIMESTAMP/
â”œâ”€â”€ best_model.pt              # Meilleur modÃ¨le (val accuracy)
â”œâ”€â”€ checkpoint_epoch_N.pt      # Checkpoints pÃ©riodiques
â”œâ”€â”€ config.json                # Configuration utilisÃ©e
â”œâ”€â”€ results.json               # RÃ©sultats finaux
â””â”€â”€ tensorboard/              # Logs TensorBoard
```

## ğŸ’¡ Conseils d'utilisation

### Quand utiliser le modÃ¨le style seul ?

âœ… **Utiliser si** :
- Focus exclusif sur la classification de style
- Budget computationnel limitÃ©
- Besoin de performances optimales sur style
- DÃ©ploiement avec contraintes mÃ©moire

âŒ **Utiliser multi-tÃ¢che si** :
- Besoin de prÃ©dire style ET artiste
- VolontÃ© de partager les reprÃ©sentations
- IntÃ©rÃªt pour le learning multi-tÃ¢che

### Optimisations possibles

1. **RÃ©duire batch size** si OOM:
   ```bash
   python train_style.py --batch-size 128
   ```

2. **Utiliser timm** si CLIP indisponible:
   ```bash
   python train_style.py --backbone-type timm
   ```

3. **RÃ©duire epochs** pour test rapide:
   ```bash
   python train_style.py --phase1-epochs 5 --phase2-epochs 10
   ```

4. **DÃ©sactiver early stopping** (modifier `DEFAULT_CONFIG`):
   ```python
   "early_stopping_patience": 999,
   ```

## ğŸ› Troubleshooting

### Erreur CUDA Out of Memory

```bash
# RÃ©duire batch size
python train_style.py --batch-size 96

# DÃ©sactiver mixed precision
python train_style.py --no-amp
```

### Convergence lente

- Augmenter learning rate phase 1 : `--phase1-lr 1e-3`
- RÃ©duire warmup : modifier `warmup_epochs` dans config
- VÃ©rifier augmentation : peut-Ãªtre trop forte

### Overfitting

- Augmenter dropout : modifier `dropout` dans config
- Augmenter weight_decay : `--weight-decay 0.1`
- Plus d'epochs en phase 1 avant fine-tuning

## ğŸ“ Citation

Si tu utilises ce code, cite le projet WikiArt :

```
WikiArt Style Classifier
Based on Vision Transformer (ViT) with CLIP pretraining
Dataset: WikiArt (63K images, 22 styles)
```

## ğŸ¤ Contribution

Pour amÃ©liorer le modÃ¨le :
1. ExpÃ©rimenter avec d'autres backbones (ViT-L, Swin Transformer)
2. Tester diffÃ©rentes augmentations
3. ImplÃ©menter des techniques avancÃ©es (MixUp, CutMix)
4. Ajouter une validation croisÃ©e
5. Optimiser les hyperparamÃ¨tres avec Optuna

## ğŸ“„ License

MÃªme license que le projet principal.
